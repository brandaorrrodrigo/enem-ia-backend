from fastapi import FastAPI, HTTPException, Request, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel, Field, validator
from typing import Optional, Dict, List
from datetime import datetime, timedelta
from collections import defaultdict
import httpx
import os
import logging
import hashlib
import asyncio

# ============================================================================
# CONFIGURAÃ‡ÃƒO DE LOGGING
# ============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# ============================================================================
# CONFIGURAÃ‡Ã•ES
# ============================================================================

OLLAMA_URL = os.getenv("OLLAMA_URL", "http://127.0.0.1:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "llama3:latest")
TIMEOUT_SECONDS = int(os.getenv("TIMEOUT_SECONDS", "90"))
MAX_RETRIES = int(os.getenv("MAX_RETRIES", "2"))
CACHE_ENABLED = os.getenv("CACHE_ENABLED", "true").lower() == "true"
CACHE_TTL_HOURS = int(os.getenv("CACHE_TTL_HOURS", "24"))

# ============================================================================
# INICIALIZAÃ‡ÃƒO DA APP
# ============================================================================

app = FastAPI(
    title="ENEM-IA API",
    version="2.0",
    description="API avanÃ§ada para explicaÃ§Ãµes pedagÃ³gicas de questÃµes do ENEM",
    docs_url="/docs",
    redoc_url="/redoc"
)

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # Em produÃ§Ã£o, especifique domÃ­nios permitidos
    allow_methods=["*"],
    allow_headers=["*"],
    allow_credentials=True,
)

# ============================================================================
# SISTEMA DE CACHE E RATE LIMITING
# ============================================================================

# Cache simples em memÃ³ria (em produÃ§Ã£o, use Redis)
cache_explicacoes: Dict[str, Dict] = {}

# Rate limiting simples
rate_limit_store: Dict[str, List[datetime]] = defaultdict(list)
RATE_LIMIT_MAX = 10  # requisiÃ§Ãµes
RATE_LIMIT_WINDOW = 60  # segundos


def limpar_cache_expirado():
    """Remove entradas expiradas do cache"""
    agora = datetime.now()
    keys_para_remover = []
    
    for key, valor in cache_explicacoes.items():
        if agora > valor["expira_em"]:
            keys_para_remover.append(key)
    
    for key in keys_para_remover:
        del cache_explicacoes[key]
        logger.info(f"ðŸ—‘ï¸ Cache expirado removido: {key[:8]}...")


def gerar_cache_key(questao_id: int, resposta: str, contexto: Optional[str]) -> str:
    """Gera chave Ãºnica para cache baseada nos parÃ¢metros"""
    dados = f"{questao_id}:{resposta}:{contexto or ''}"
    return hashlib.sha256(dados.encode()).hexdigest()


def verificar_rate_limit(ip: str) -> bool:
    """Verifica se IP excedeu o rate limit"""
    agora = datetime.now()
    janela_inicio = agora - timedelta(seconds=RATE_LIMIT_WINDOW)
    
    # Remove requisiÃ§Ãµes antigas
    rate_limit_store[ip] = [
        timestamp for timestamp in rate_limit_store[ip]
        if timestamp > janela_inicio
    ]
    
    # Verifica limite
    if len(rate_limit_store[ip]) >= RATE_LIMIT_MAX:
        return False
    
    # Adiciona nova requisiÃ§Ã£o
    rate_limit_store[ip].append(agora)
    return True

# ============================================================================
# MODELOS PYDANTIC
# ============================================================================

class ExplicarReq(BaseModel):
    questao_id: int = Field(..., ge=1, description="ID da questÃ£o (maior que 0)")
    resposta_usuario: str = Field(..., min_length=1, max_length=1, description="Alternativa marcada (A-E)")
    resposta_correta: Optional[str] = Field(None, min_length=1, max_length=1, description="Gabarito correto (A-E)")
    enunciado: Optional[str] = Field(None, max_length=5000, description="Texto da questÃ£o (opcional)")
    disciplina: Optional[str] = Field(None, description="Disciplina da questÃ£o")
    assunto: Optional[str] = Field(None, description="Assunto especÃ­fico")
    dificuldade: Optional[str] = Field(None, description="NÃ­vel de dificuldade")
    contexto_adicional: Optional[str] = Field(None, max_length=1000, description="InformaÃ§Ãµes extras")
    
    @validator('resposta_usuario', 'resposta_correta')
    def validar_alternativa(cls, v):
        if v and v.upper() not in ['A', 'B', 'C', 'D', 'E']:
            raise ValueError("Alternativa deve ser A, B, C, D ou E")
        return v.upper() if v else None
    
    @validator('disciplina')
    def validar_disciplina(cls, v):
        disciplinas_validas = [
            'matematica', 'fisica', 'quimica', 'biologia',
            'historia', 'geografia', 'portugues', 'literatura',
            'filosofia', 'sociologia', 'ingles', 'espanhol'
        ]
        if v and v.lower() not in disciplinas_validas:
            raise ValueError(f"Disciplina deve ser uma de: {', '.join(disciplinas_validas)}")
        return v.lower() if v else None


class ExplicacaoResponse(BaseModel):
    ok: bool = True
    explicacao: str
    questao_id: int
    cached: bool = False
    tempo_processamento: float
    modelo_usado: str
    timestamp: str
    resposta_era_correta: Optional[bool] = None
    nivel_confianca: Optional[str] = None


class HealthResponse(BaseModel):
    status: str
    ollama_disponivel: bool
    ollama_url: str
    modelo: str
    cache_entries: int
    timestamp: str

# ============================================================================
# FUNÃ‡Ã•ES AUXILIARES
# ============================================================================

async def verificar_ollama_disponivel() -> bool:
    """Verifica se o Ollama estÃ¡ acessÃ­vel"""
    try:
        async with httpx.AsyncClient(timeout=5.0) as client:
            response = await client.get(f"{OLLAMA_URL}/api/tags")
            return response.status_code == 200
    except Exception as e:
        logger.error(f"Ollama nÃ£o disponÃ­vel: {str(e)}")
        return False


def construir_prompt_detalhado(req: ExplicarReq) -> str:
    """ConstrÃ³i prompt pedagÃ³gico personalizado"""
    
    # InformaÃ§Ãµes contextuais
    contexto = ""
    if req.disciplina:
        contexto += f"\nðŸ“š Disciplina: {req.disciplina.title()}"
    if req.assunto:
        contexto += f"\nðŸ“– Assunto: {req.assunto}"
    if req.dificuldade:
        contexto += f"\nâ­ Dificuldade: {req.dificuldade}"
    
    # InformaÃ§Ã£o sobre acerto/erro
    resultado = ""
    if req.resposta_correta:
        acertou = req.resposta_usuario == req.resposta_correta
        resultado = f"\nâœ… O aluno {'ACERTOU' if acertou else 'ERROU'} a questÃ£o."
        resultado += f"\nðŸŽ¯ Resposta correta: {req.resposta_correta}"
        resultado += f"\nâŒ Resposta do aluno: {req.resposta_usuario}"
    
    # Enunciado
    enunciado_texto = ""
    if req.enunciado:
        enunciado_texto = f"\n\nðŸ“ **Enunciado da questÃ£o:**\n{req.enunciado}"
    
    # Contexto adicional
    adicional = ""
    if req.contexto_adicional:
        adicional = f"\n\nðŸ’¡ **InformaÃ§Ãµes adicionais:**\n{req.contexto_adicional}"
    
    prompt = f"""VocÃª Ã© um professor EXPERIENTE e EMPÃTICO do ENEM, especializado em explicaÃ§Ãµes pedagÃ³gicas claras e motivadoras.

ðŸ“‹ **INFORMAÃ‡Ã•ES DA QUESTÃƒO:**
ðŸ†” QuestÃ£o #{req.questao_id}{contexto}{resultado}{enunciado_texto}{adicional}

ðŸŽ¯ **SUA MISSÃƒO:**
Gerar uma explicaÃ§Ã£o COMPLETA, DIDÃTICA e MOTIVADORA que ajude o aluno a:
1. Entender onde errou (se errou) ou por que acertou
2. Compreender o conceito fundamental
3. Fixar o conhecimento para nÃ£o errar novamente
4. Conectar com outros tÃ³picos do ENEM

ðŸ“ **ESTRUTURA OBRIGATÃ“RIA DA RESPOSTA:**

**1ï¸âƒ£ ANÃLISE DA RESPOSTA** {'(ðŸŽ‰ ParabÃ©ns!)' if req.resposta_correta and req.resposta_usuario == req.resposta_correta else ''}
{f'- O aluno marcou: {req.resposta_usuario}' if req.resposta_usuario else ''}
{f'- A resposta correta Ã©: {req.resposta_correta}' if req.resposta_correta else ''}
- Explique de forma gentil e motivadora o que aconteceu

**2ï¸âƒ£ CONCEITO FUNDAMENTAL**
- Qual Ã© o conceito/teoria/regra principal dessa questÃ£o?
- Explique com clareza, usando linguagem acessÃ­vel
- Use NEGRITO para destacar termos importantes

**3ï¸âƒ£ PASSO A PASSO DA RESOLUÃ‡ÃƒO**
- Detalhe o raciocÃ­nio completo que leva Ã  resposta correta
- Use nÃºmeros ou marcadores para organizar
- Seja progressivo: do mais simples ao mais complexo

**4ï¸âƒ£ EXEMPLO PRÃTICO DO DIA A DIA** ðŸŒŸ
- SEMPRE crie uma analogia com situaÃ§Ã£o cotidiana
- Exemplos: compras no mercado, preparar comida, usar celular, dirigir, esportes, corpo humano, natureza
- FaÃ§a a conexÃ£o ser Ã“BVIA e MEMORÃVEL

**5ï¸âƒ£ CONEXÃ•ES COM OUTROS TÃ“PICOS** ðŸ”—
- Cite 2-3 outros assuntos/questÃµes do ENEM que usam raciocÃ­nio similar
- Mostre como esse conhecimento se conecta com outras disciplinas

**6ï¸âƒ£ DICA DE MEMORIZAÃ‡ÃƒO** ðŸ’¡
- Ensine um MACETE para lembrar desse conceito
- Pode ser: sigla, frase curta, rima, imagem mental, regra prÃ¡tica
- FaÃ§a ser SIMPLES e INESQUECÃVEL

**7ï¸âƒ£ EXERCÃCIO MENTAL RÃPIDO** ðŸ§ 
- Proponha UMA pergunta simples para o aluno se auto-testar
- Deve reforÃ§ar o conceito aprendido

**8ï¸âƒ£ MENSAGEM MOTIVACIONAL** ðŸ’ª
- Finalize com incentivo genuÃ­no e personalizado
- Mostre que errar faz parte do aprendizado
- Encoraje o aluno a continuar estudando

**9ï¸âƒ£ VERIFICAÃ‡ÃƒO DE ENTENDIMENTO**
- Pergunte: "Ficou claro? Quer que eu explique de outra forma?"

âš ï¸ **REGRAS IMPORTANTES:**
- Use linguagem acessÃ­vel (nÃ­vel ensino mÃ©dio)
- Seja empÃ¡tico e motivador, NUNCA punitivo
- Use emojis para tornar a leitura agradÃ¡vel
- Seja conciso mas completo (nÃ£o seja prolixo)
- Adapte exemplos Ã  disciplina da questÃ£o
- SEMPRE termine com pergunta de verificaÃ§Ã£o

ðŸ’š Lembre-se: vocÃª estÃ¡ ajudando um jovem a conquistar seu sonho de entrar na universidade!"""

    return prompt


async def chamar_ollama_com_retry(
    prompt: str,
    max_tentativas: int = MAX_RETRIES
) -> str:
    """
    Chama Ollama com sistema de retry em caso de falha
    """
    ultima_excecao = None
    
    for tentativa in range(max_tentativas):
        try:
            logger.info(f"ðŸ¤– Tentativa {tentativa + 1}/{max_tentativas} - Chamando Ollama")
            
            async with httpx.AsyncClient(timeout=TIMEOUT_SECONDS) as client:
                response = await client.post(
                    f"{OLLAMA_URL}/api/generate",
                    json={
                        "model": OLLAMA_MODEL,
                        "prompt": prompt,
                        "stream": False,
                        "options": {
                            "temperature": 0.7,
                            "top_p": 0.9,
                        }
                    }
                )
                
                response.raise_for_status()
                data = response.json()
                
                # Extrai o texto da resposta
                texto = data.get("response") or data.get("text") or ""
                
                if not texto or len(texto.strip()) < 50:
                    raise ValueError("Resposta muito curta ou vazia da IA")
                
                logger.info(f"âœ… Ollama respondeu com sucesso ({len(texto)} chars)")
                return texto.strip()
                
        except httpx.TimeoutException as e:
            ultima_excecao = e
            logger.warning(f"â±ï¸ Timeout na tentativa {tentativa + 1}")
            if tentativa < max_tentativas - 1:
                await asyncio.sleep(2)  # Aguarda antes de tentar novamente
                continue
                
        except httpx.HTTPStatusError as e:
            ultima_excecao = e
            logger.error(f"âŒ Erro HTTP {e.response.status_code}")
            if tentativa < max_tentativas - 1:
                await asyncio.sleep(2)
                continue
                
        except Exception as e:
            ultima_excecao = e
            logger.error(f"ðŸ’¥ Erro inesperado: {str(e)}")
            if tentativa < max_tentativas - 1:
                await asyncio.sleep(2)
                continue
    
    # Se chegou aqui, todas tentativas falharam
    erro_msg = f"Falha apÃ³s {max_tentativas} tentativas. Ãšltimo erro: {str(ultima_excecao)}"
    logger.error(f"ðŸ’¥ {erro_msg}")
    raise HTTPException(status_code=503, detail=erro_msg)

# ============================================================================
# ENDPOINTS
# ============================================================================

@app.get("/", response_model=Dict)
async def root():
    """InformaÃ§Ãµes bÃ¡sicas da API"""
    return {
        "service": "ENEM-IA API",
        "version": "2.0",
        "status": "online",
        "endpoints": {
            "explicar": "/explicar (POST)",
            "reexplicar": "/reexplicar (POST)",
            "health": "/health (GET)",
            "cache_stats": "/cache/stats (GET)",
            "docs": "/docs",
        },
        "timestamp": datetime.now().isoformat()
    }


@app.get("/health", response_model=HealthResponse)
async def health_check():
    """Verifica saÃºde da API e disponibilidade do Ollama"""
    ollama_ok = await verificar_ollama_disponivel()
    
    return HealthResponse(
        status="healthy" if ollama_ok else "degraded",
        ollama_disponivel=ollama_ok,
        ollama_url=OLLAMA_URL,
        modelo=OLLAMA_MODEL,
        cache_entries=len(cache_explicacoes),
        timestamp=datetime.now().isoformat()
    )


@app.get("/cache/stats")
async def cache_stats(background_tasks: BackgroundTasks):
    """EstatÃ­sticas do cache"""
    background_tasks.add_task(limpar_cache_expirado)
    
    return {
        "cache_enabled": CACHE_ENABLED,
        "total_entries": len(cache_explicacoes),
        "ttl_hours": CACHE_TTL_HOURS,
        "timestamp": datetime.now().isoformat()
    }


@app.delete("/cache/clear")
async def limpar_cache():
    """Limpa todo o cache (Ãºtil para desenvolvimento)"""
    cache_explicacoes.clear()
    logger.info("ðŸ—‘ï¸ Cache limpo manualmente")
    return {"message": "Cache limpo com sucesso", "timestamp": datetime.now().isoformat()}


@app.post("/explicar", response_model=ExplicacaoResponse)
async def explicar(
    req: ExplicarReq,
    request: Request,
    background_tasks: BackgroundTasks
):
    """
    Gera explicaÃ§Ã£o pedagÃ³gica detalhada e personalizada para uma questÃ£o do ENEM.
    """
    inicio = datetime.now()
    ip_cliente = request.client.host if request.client else "unknown"
    
    # Verificar rate limit
    if not verificar_rate_limit(ip_cliente):
        logger.warning(f"âš ï¸ Rate limit excedido para IP: {ip_cliente}")
        raise HTTPException(
            status_code=429,
            detail=f"Limite de {RATE_LIMIT_MAX} requisiÃ§Ãµes por {RATE_LIMIT_WINDOW}s excedido. Aguarde um momento."
        )
    
    logger.info(f"ðŸ“¨ Nova requisiÃ§Ã£o de explicaÃ§Ã£o - QuestÃ£o #{req.questao_id} - IP: {ip_cliente}")
    
    # Limpar cache expirado em background
    background_tasks.add_task(limpar_cache_expirado)
    
    # Verificar cache
    cache_key = gerar_cache_key(
        req.questao_id,
        req.resposta_usuario,
        req.contexto_adicional
    )
    
    if CACHE_ENABLED and cache_key in cache_explicacoes:
        cache_entry = cache_explicacoes[cache_key]
        if datetime.now() < cache_entry["expira_em"]:
            tempo_processamento = (datetime.now() - inicio).total_seconds()
            logger.info(f"ðŸ’¾ Cache HIT para questÃ£o #{req.questao_id}")
            
            return ExplicacaoResponse(
                ok=True,
                explicacao=cache_entry["explicacao"],
                questao_id=req.questao_id,
                cached=True,
                tempo_processamento=tempo_processamento,
                modelo_usado=OLLAMA_MODEL,
                timestamp=datetime.now().isoformat(),
                resposta_era_correta=(
                    req.resposta_usuario == req.resposta_correta
                    if req.resposta_correta else None
                )
            )
    
    # Cache miss - gerar nova explicaÃ§Ã£o
    logger.info(f"ðŸ”„ Cache MISS - Gerando nova explicaÃ§Ã£o")
    
    try:
        # Construir prompt
        prompt = construir_prompt_detalhado(req)
        
        # Chamar Ollama
        explicacao = await chamar_ollama_com_retry(prompt)
        
        # Calcular tempo de processamento
        tempo_processamento = (datetime.now() - inicio).total_seconds()
        
        # Salvar no cache se habilitado
        if CACHE_ENABLED:
            cache_explicacoes[cache_key] = {
                "explicacao": explicacao,
                "expira_em": datetime.now() + timedelta(hours=CACHE_TTL_HOURS),
                "criado_em": datetime.now().isoformat()
            }
            logger.info(f"ðŸ’¾ ExplicaÃ§Ã£o salva no cache")
        
        logger.info(f"âœ… ExplicaÃ§Ã£o gerada com sucesso em {tempo_processamento:.2f}s")
        
        return ExplicacaoResponse(
            ok=True,
            explicacao=explicacao,
            questao_id=req.questao_id,
            cached=False,
            tempo_processamento=tempo_processamento,
            modelo_usado=OLLAMA_MODEL,
            timestamp=datetime.now().isoformat(),
            resposta_era_correta=(
                req.resposta_usuario == req.resposta_correta
                if req.resposta_correta else None
            ),
            nivel_confianca="alto"
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Erro ao gerar explicaÃ§Ã£o: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao gerar explicaÃ§Ã£o: {str(e)}"
        )


@app.post("/reexplicar", response_model=ExplicacaoResponse)
async def reexplicar(
    req: ExplicarReq,
    request: Request,
    background_tasks: BackgroundTasks
):
    """
    Segunda explicaÃ§Ã£o, mais simples, com exemplos ainda mais prÃ¡ticos.
    """
    inicio = datetime.now()
    ip_cliente = request.client.host if request.client else "unknown"
    
    if not verificar_rate_limit(ip_cliente):
        logger.warning(f"âš ï¸ Rate limit excedido para IP: {ip_cliente}")
        raise HTTPException(
            status_code=429,
            detail=f"Limite de {RATE_LIMIT_MAX} requisiÃ§Ãµes por {RATE_LIMIT_WINDOW}s excedido. Aguarde um momento."
        )

    logger.info(f"ðŸ“¨ Nova requisiÃ§Ã£o de REEXPLICAÃ‡ÃƒO - QuestÃ£o #{req.questao_id} - IP: {ip_cliente}")
    background_tasks.add_task(limpar_cache_expirado)

    # Prompt especial pra reexplicaÃ§Ã£o
    contexto_disc = f"Disciplina: {req.disciplina}" if req.disciplina else ""
    prompt = f"""
VocÃª Ã© um professor extremamente didÃ¡tico explicando de NOVO uma questÃ£o do ENEM para um aluno que nÃ£o entendeu ainda.

QuestÃ£o #{req.questao_id}
{contexto_disc}

Enunciado (resumido, se disponÃ­vel):
{req.enunciado or "[enunciado nÃ£o enviado]"}

O aluno marcou a alternativa: {req.resposta_usuario}
Gabarito oficial: {req.resposta_correta or "nÃ£o informado"}

Ele jÃ¡ recebeu uma explicaÃ§Ã£o antes, mas NÃƒO ENTENDEU.
Agora vocÃª vai explicar de um jeito AINDA MAIS SIMPLES, seguindo este formato:

1) REEXPLICAÃ‡ÃƒO BEM SIMPLES
- Explique como se estivesse falando com um amigo usando exemplos do dia a dia
- Frases curtas, diretas, sem jargÃ£o tÃ©cnico desnecessÃ¡rio

2) ANALOGIA DO COTIDIANO
- Crie pelo menos UMA analogia forte (mercado, esporte, trÃ¢nsito, redes sociais, celular, etc)
- Ela tem que ser tÃ£o simples que atÃ© alguÃ©m cansado conseguiria entender

3) OUTRO EXEMPLO DE QUESTÃƒO
- Invente um exemplo parecido com a mesma base de conhecimento
- Mostre como resolver esse exemplo passo a passo

4) ONDE AS PESSOAS COSTUMAM ERRAR
- Liste 2 ou 3 erros comuns nessa ideia/conteÃºdo
- Explique como evitar esses erros

5) RESUMÃƒO FINAL EM 3 LINHAS
- FaÃ§a um micro-resumo em atÃ© 3 frases
- Como se fosse um post curto para lembrar antes da prova

6) PERGUNTA DE CHECAGEM
- Termine perguntando: "Agora ficou mais claro? Quer tentar um desafio comigo?"

Use linguagem brasileira, prÃ³xima da realidade do aluno do ensino mÃ©dio.
Use emoji com moderaÃ§Ã£o, sÃ³ para deixar mais leve.
"""

    try:
        explicacao = await chamar_ollama_com_retry(prompt)
        tempo_processamento = (datetime.now() - inicio).total_seconds()

        return ExplicacaoResponse(
            ok=True,
            explicacao=explicacao,
            questao_id=req.questao_id,
            cached=False,
            tempo_processamento=tempo_processamento,
            modelo_usado=OLLAMA_MODEL,
            timestamp=datetime.now().isoformat(),
            resposta_era_correta=(
                req.resposta_usuario == req.resposta_correta
                if req.resposta_correta else None
            ),
            nivel_confianca="alto"
        )
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ Erro ao gerar REEXPLICAÃ‡ÃƒO: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail=f"Erro ao gerar REEXPLICAÃ‡ÃƒO: {str(e)}"
        )

# ============================================================================
# EXCEPTION HANDLERS
# ============================================================================

@app.exception_handler(HTTPException)
async def http_exception_handler(request: Request, exc: HTTPException):
    """Handler customizado para HTTPException"""
    logger.error(f"HTTPException: {exc.status_code} - {exc.detail}")
    return JSONResponse(
        status_code=exc.status_code,
        content={
            "ok": False,
            "error": exc.detail,
            "status_code": exc.status_code,
            "timestamp": datetime.now().isoformat()
        }
    )


@app.exception_handler(Exception)
async def generic_exception_handler(request: Request, exc: Exception):
    """Handler genÃ©rico para exceÃ§Ãµes nÃ£o tratadas"""
    logger.error(f"ExceÃ§Ã£o nÃ£o tratada: {type(exc).__name__} - {str(exc)}", exc_info=True)
    return JSONResponse(
        status_code=500,
        content={
            "ok": False,
            "error": "Erro interno do servidor",
            "details": str(exc) if os.getenv("DEBUG") else None,
            "timestamp": datetime.now().isoformat()
        }
    )


# ============================================================================
# STARTUP & SHUTDOWN EVENTS
# ============================================================================

@app.on_event("startup")
async def startup_event():
    """Executado ao iniciar a aplicaÃ§Ã£o"""
    logger.info("=" * 70)
    logger.info("ðŸš€ ENEM-IA API v2.0 INICIADA")
    logger.info("=" * 70)
    logger.info(f"ðŸ¤– Ollama URL: {OLLAMA_URL}")
    logger.info(f"ðŸ§  Modelo: {OLLAMA_MODEL}")
    logger.info(f"â±ï¸  Timeout: {TIMEOUT_SECONDS}s")
    logger.info(f"ðŸ”„ Max Retries: {MAX_RETRIES}")
    logger.info(f"ðŸ’¾ Cache: {'Habilitado' if CACHE_ENABLED else 'Desabilitado'}")
    if CACHE_ENABLED:
        logger.info(f"â° Cache TTL: {CACHE_TTL_HOURS}h")
    logger.info(f"ðŸš¦ Rate Limit: {RATE_LIMIT_MAX} req/{RATE_LIMIT_WINDOW}s")
    logger.info(f"ðŸ“– Docs: http://localhost:8000/docs")
    logger.info("=" * 70)
    
    # Verificar disponibilidade do Ollama
    ollama_ok = await verificar_ollama_disponivel()
    if ollama_ok:
        logger.info("âœ… Ollama estÃ¡ disponÃ­vel e funcionando")
    else:
        logger.warning("âš ï¸ Ollama nÃ£o estÃ¡ disponÃ­vel - verifique a configuraÃ§Ã£o")


@app.on_event("shutdown")
async def shutdown_event():
    """Executado ao encerrar a aplicaÃ§Ã£o"""
    logger.info("ðŸ›‘ ENEM-IA API encerrada")
    logger.info(f"ðŸ“Š EstatÃ­sticas finais: {len(cache_explicacoes)} entradas no cache")


# ============================================================================
# MAIN
# ============================================================================

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        log_level="info",
        access_log=True
    )
